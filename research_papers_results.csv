Timestamp,Filename,Title,Authors,Research Area,Relevance Score,Key Findings,Methodology,Performance Metrics,Recommended Action
2026-02-06 22:06:03,Lotus Characterize Architecture.pdf,Lotus: Characterize Architecture Level CPU-based Preprocessing in Machine Learning Pipelines,"Rajveer Bachkaniwala, Harshith Lanka, Kexin Rong, Ada Gavrilovska",Data Pipelines,9,"Preprocessing tasks in ML pipelines are a significant bottleneck, consuming substantial compute and power resources, and their performance is closely tied to CPU microarchitecture. Lotus, an open-source profiling tool, bridges the gap between high-level Python preprocessing functions and low-level CPU hardware metrics, revealing architectural bottlenecks. It demonstrates that increasing data loader workers can reduce end-to-end job time but may increase overall CPU time due to hardware resource contention, highlighting the importance of CPU SKU selection.","The research introduces Lotus, a profiling tool with two components: LotusTrace for lightweight instrumentation and tracing of ML preprocessing workloads, and LotusMap for approximating the mapping of Python functions to their C/C++ counterparts. Lotus leverages existing hardware profilers (e.g., Intel VTune) to collect microarchitectural performance data and attributes these to specific preprocessing operations. Experiments are conducted on an Image Classification task using PyTorch's DataLoader, varying the number of data loader workers on a CloudLab node with Intel Xeon CPUs and NVIDIA V100 GPUs.","Observed a ~50% drop in end-to-end job elapsed time as data loaders increased from 8 to 28, with diminishing returns beyond 20. Total CPU seconds increased by 53% from 8 to 28 data loaders. Revealed a steep undersupply of uOperations to the backend and decreased pressure on stalls caused by loads serviced by Local DRAM with increasing data loaders.",Deep Read
2026-02-06 22:17:03,Lotus Characterize Architecture.pdf,Lotus: Characterize Architecture Level CPU-based Preprocessing in Machine Learning Pipelines,"Rajveer Bachkaniwala, Harshith Lanka, Kexin Rong, Ada Gavrilovska",Data Pipelines,9,"Lotus, an open-source profiling tool, bridges the gap between high-level Python ML preprocessing functions and low-level CPU architectural performance counters. It reveals that increasing data loader workers can lead to diminishing returns in end-to-end job time reduction while increasing overall CPU time due to hardware resource contention, particularly front-end bound microarchitectural stalls.","The research introduces Lotus, comprising LotusTrace for lightweight instrumentation and tracing of ML preprocessing workloads, and LotusMap for approximating the mapping of Python functions to C/C++ counterparts to attribute hardware events. Experiments were conducted on an Image Classification task using PyTorch's DataLoader, ImageNet, and ResNet18 on a CloudLab node with Intel Xeon CPUs and NVIDIA V100 GPUs, varying the number of data loader workers.","~50% drop in E2E job elapsed time as dataloaders increased from 8 to 28, with diminishing returns beyond 20. Total CPU seconds increased by 53% from 8 to 28 data loaders. Revealed steep undersupply of uOperations to the backend and decreased stalls from Local DRAM loads.",Deep Read
